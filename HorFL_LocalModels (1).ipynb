{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d6b9910-ef51-4a12-939e-cdbe4e461fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "\n",
    "sns.set(style='darkgrid')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87f9fff-586c-423b-b5e1-66a70cdc7a15",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbefdff1-a2ef-4e13-aa16-a215e1350ebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(504159, 36)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client_1_data = pd.read_csv(\"Sisira Horizontal/trial new/Horizontally splitted data/client_1_data.csv\")\n",
    "client_1_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9bfcb21-a375-4192-864e-bfe38c85fb66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(504159, 36)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client_2_data = pd.read_csv(\"Sisira Horizontal/trial new/Horizontally splitted data/client_2_data.csv\")\n",
    "client_2_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46118cf7-99c6-497e-8973-51a7dbb167b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(504159, 36)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client_3_data = pd.read_csv(\"Sisira Horizontal/trial new/Horizontally splitted data/client_3_data.csv\")\n",
    "client_3_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04f15223-7d5c-455b-9dad-c53a3d9e523c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(504159, 36)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client_4_data = pd.read_csv(\"Sisira Horizontal/trial new/Horizontally splitted data/client_4_data.csv\")\n",
    "client_4_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2c4c93a-9ca9-47af-9016-bf75e5711a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(504159, 36)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client_5_data = pd.read_csv(\"Sisira Horizontal/trial new/Horizontally splitted data/client_5_data.csv\")\n",
    "client_5_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f6d322-149f-4020-a159-0d8c4aeadb87",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85b044a1-901d-4827-a00f-eea27111af0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path=\"Sisira /trial new/Fresh_models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6ac590f-f16c-45a6-b744-07915c473049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model for Client 1 saved as 'client_1_model.pkl'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/jupyter/dtids.user01/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Client 1:\n",
      " [[83728     9     1     3    16     0    43     0]\n",
      " [   40    33     0     0     0     0     0     0]\n",
      " [    5     0   377     0     0     0     0     1]\n",
      " [    1     0     0  5146     3     0     0     0]\n",
      " [   41     0     0     0  7595     0     0     0]\n",
      " [    1     0     0     0     0     0     0     0]\n",
      " [   25     0     0     0     4     0  3666     0]\n",
      " [    6     0     3     0     0     0     0    85]]\n",
      "Accuracy for Client 1: 99.80%\n",
      "Precision for Client 1: 1.00\n",
      "Recall for Client 1: 1.00\n",
      "F1 Score for Client 1: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/jupyter/dtids.user01/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/jupyter/dtids.user01/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detailed Classification Report for Client 1:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      BENIGN       1.00      1.00      1.00     83800\n",
      "         Bot       0.79      0.45      0.57        73\n",
      " Brute Force       0.99      0.98      0.99       383\n",
      "        DDoS       1.00      1.00      1.00      5150\n",
      "         DoS       1.00      0.99      1.00      7636\n",
      "Infiltration       0.00      0.00      0.00         1\n",
      "   Port Scan       0.99      0.99      0.99      3695\n",
      "  Web Attack       0.99      0.90      0.94        94\n",
      "\n",
      "    accuracy                           1.00    100832\n",
      "   macro avg       0.84      0.79      0.81    100832\n",
      "weighted avg       1.00      1.00      1.00    100832\n",
      "\n",
      "\n",
      "True Positives for Client 1: 100630\n",
      "False Positives for Client 1: 202\n",
      "True Negatives for Client 1: 1212\n",
      "False Negatives for Client 1: 202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/jupyter/dtids.user01/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Load Client 1's horizontally split data\n",
    "client1_data = pd.read_csv(\"Sisira /trial new/client_1_data.csv\")  # Update the file path for Client 1's dataset\n",
    "\n",
    "# Separate features and target\n",
    "X = client1_data.drop(columns=[\"Attack Type\"])  # All columns except 'Attack Type' (features)\n",
    "y = client1_data[\"Attack Type\"]  # 'Attack Type' is the target\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize Random Forest Classifier\n",
    "rf_model_client1 = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_model_client1.fit(X_train, y_train)\n",
    "\n",
    "# Save the trained model as a .pkl file\n",
    "model_filename = \"client_1_model.pkl\"\n",
    "joblib.dump(rf_model_client1, f\"{base_path}/{model_filename}\")\n",
    "print(f\"Trained model for Client 1 saved as '{model_filename}'\")\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_client1 = rf_model_client1.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_client1 = accuracy_score(y_test, y_pred_client1)\n",
    "precision_client1 = precision_score(y_test, y_pred_client1, average=\"weighted\")\n",
    "recall_client1 = recall_score(y_test, y_pred_client1, average=\"weighted\")\n",
    "f1_client1 = f1_score(y_test, y_pred_client1, average=\"weighted\")\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix_client1 = confusion_matrix(y_test, y_pred_client1)\n",
    "\n",
    "# Extracting True Positives, False Positives, True Negatives, and False Negatives\n",
    "TP_client1 = conf_matrix_client1.diagonal().sum()  # True Positives (Sum of diagonal values)\n",
    "FP_client1 = conf_matrix_client1.sum(axis=0) - conf_matrix_client1.diagonal()  # False Positives\n",
    "FN_client1 = conf_matrix_client1.sum(axis=1) - conf_matrix_client1.diagonal()  # False Negatives\n",
    "TN_client1 = conf_matrix_client1.sum() - (FP_client1 + FN_client1 + TP_client1)  # True Negatives\n",
    "\n",
    "# Print metrics\n",
    "print(\"Confusion Matrix for Client 1:\\n\", conf_matrix_client1)\n",
    "print(f\"Accuracy for Client 1: {accuracy_client1 * 100:.2f}%\")\n",
    "print(f\"Precision for Client 1: {precision_client1:.2f}\")\n",
    "print(f\"Recall for Client 1: {recall_client1:.2f}\")\n",
    "print(f\"F1 Score for Client 1: {f1_client1:.2f}\")\n",
    "\n",
    "print(\"\\nDetailed Classification Report for Client 1:\\n\", classification_report(y_test, y_pred_client1))\n",
    "\n",
    "print(\"\\nTrue Positives for Client 1:\", TP_client1)\n",
    "print(\"False Positives for Client 1:\", FP_client1.sum())\n",
    "print(\"True Negatives for Client 1:\", TN_client1.sum())\n",
    "print(\"False Negatives for Client 1:\", FN_client1.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75bc9c5d-b044-4065-9737-e261967c1be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model for Client 2 saved as 'client_2_model.pkl'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/jupyter/dtids.user01/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Client 2:\n",
      " [[83976     8     1     0    12     0    50     0]\n",
      " [   43    35     0     0     0     0     0     0]\n",
      " [    5     0   364     0     1     0     0     1]\n",
      " [    5     0     0  5117     0     0     0     0]\n",
      " [   48     0     0     1  7522     0     0     0]\n",
      " [    2     0     0     0     0     0     0     0]\n",
      " [   23     0     0     0     2     0  3533     0]\n",
      " [    4     0     0     0     1     0     0    78]]\n",
      "Accuracy for Client 2: 99.79%\n",
      "Precision for Client 2: 1.00\n",
      "Recall for Client 2: 1.00\n",
      "F1 Score for Client 2: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/jupyter/dtids.user01/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/jupyter/dtids.user01/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detailed Classification Report for Client 2:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      BENIGN       1.00      1.00      1.00     84047\n",
      "         Bot       0.81      0.45      0.58        78\n",
      " Brute Force       1.00      0.98      0.99       371\n",
      "        DDoS       1.00      1.00      1.00      5122\n",
      "         DoS       1.00      0.99      1.00      7571\n",
      "Infiltration       0.00      0.00      0.00         2\n",
      "   Port Scan       0.99      0.99      0.99      3558\n",
      "  Web Attack       0.99      0.94      0.96        83\n",
      "\n",
      "    accuracy                           1.00    100832\n",
      "   macro avg       0.85      0.79      0.81    100832\n",
      "weighted avg       1.00      1.00      1.00    100832\n",
      "\n",
      "\n",
      "True Positives for Client 2: 100625\n",
      "False Positives for Client 2: 207\n",
      "True Negatives for Client 2: 1242\n",
      "False Negatives for Client 2: 207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/jupyter/dtids.user01/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Load Client 2's horizontally split data\n",
    "client2_data = pd.read_csv(\"Sisira /trial new/client_2_data.csv\")  # Update the file path for Client 2's dataset\n",
    "\n",
    "# Separate features and target\n",
    "X = client2_data.drop(columns=[\"Attack Type\"])  # All columns except 'Attack Type' (features)\n",
    "y = client2_data[\"Attack Type\"]  # 'Attack Type' is the target\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize Random Forest Classifier\n",
    "rf_model_client2 = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_model_client2.fit(X_train, y_train)\n",
    "\n",
    "# Save the trained model as a .pkl file\n",
    "model_filename = \"client_2_model.pkl\"\n",
    "joblib.dump(rf_model_client2, f\"{base_path}/{model_filename}\")\n",
    "print(f\"Trained model for Client 2 saved as '{model_filename}'\")\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_client2 = rf_model_client2.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_client2 = accuracy_score(y_test, y_pred_client2)\n",
    "precision_client2 = precision_score(y_test, y_pred_client2, average=\"weighted\")\n",
    "recall_client2 = recall_score(y_test, y_pred_client2, average=\"weighted\")\n",
    "f1_client2 = f1_score(y_test, y_pred_client2, average=\"weighted\")\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix_client2 = confusion_matrix(y_test, y_pred_client2)\n",
    "\n",
    "# Extract True Positives, False Positives, True Negatives, and False Negatives\n",
    "TP_client2 = conf_matrix_client2.diagonal().sum()\n",
    "FP_client2 = conf_matrix_client2.sum(axis=0) - conf_matrix_client2.diagonal()\n",
    "FN_client2 = conf_matrix_client2.sum(axis=1) - conf_matrix_client2.diagonal()\n",
    "TN_client2 = conf_matrix_client2.sum() - (FP_client2 + FN_client2 + TP_client2)\n",
    "\n",
    "# Print metrics\n",
    "print(\"Confusion Matrix for Client 2:\\n\", conf_matrix_client2)\n",
    "print(f\"Accuracy for Client 2: {accuracy_client2 * 100:.2f}%\")\n",
    "print(f\"Precision for Client 2: {precision_client2:.2f}\")\n",
    "print(f\"Recall for Client 2: {recall_client2:.2f}\")\n",
    "print(f\"F1 Score for Client 2: {f1_client2:.2f}\")\n",
    "\n",
    "print(\"\\nDetailed Classification Report for Client 2:\\n\", classification_report(y_test, y_pred_client2))\n",
    "\n",
    "print(\"\\nTrue Positives for Client 2:\", TP_client2)\n",
    "print(\"False Positives for Client 2:\", FP_client2.sum())\n",
    "print(\"True Negatives for Client 2:\", TN_client2.sum())\n",
    "print(\"False Negatives for Client 2:\", FN_client2.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4dd4e51-d295-4525-b66a-44796173ee51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model for Client 3 saved as 'client_3_model.pkl'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/jupyter/dtids.user01/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Client 3:\n",
      " [[83579    19     2     0    13     0     0    54     1]\n",
      " [   29    48     0     0     0     0     0     0     0]\n",
      " [    6     0   388     0     0     0     0     0     1]\n",
      " [    5     0     0  5130     1     0     0     0     0]\n",
      " [   45     0     0     0  7774     0     0     0     0]\n",
      " [    2     0     0     0     0     0     0     0     0]\n",
      " [    1     0     0     0     0     0     0     0     0]\n",
      " [   20     0     0     0     1     0     0  3630     1]\n",
      " [    6     0     0     0     0     0     0     0    76]]\n",
      "Accuracy for Client 3: 99.79%\n",
      "Precision for Client 3: 1.00\n",
      "Recall for Client 3: 1.00\n",
      "F1 Score for Client 3: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/jupyter/dtids.user01/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/jupyter/dtids.user01/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detailed Classification Report for Client 3:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      BENIGN       1.00      1.00      1.00     83668\n",
      "         Bot       0.72      0.62      0.67        77\n",
      " Brute Force       0.99      0.98      0.99       395\n",
      "        DDoS       1.00      1.00      1.00      5136\n",
      "         DoS       1.00      0.99      1.00      7819\n",
      "  Heartbleed       0.00      0.00      0.00         2\n",
      "Infiltration       0.00      0.00      0.00         1\n",
      "   Port Scan       0.99      0.99      0.99      3652\n",
      "  Web Attack       0.96      0.93      0.94        82\n",
      "\n",
      "    accuracy                           1.00    100832\n",
      "   macro avg       0.74      0.72      0.73    100832\n",
      "weighted avg       1.00      1.00      1.00    100832\n",
      "\n",
      "\n",
      "True Positives for Client 3: 100625\n",
      "False Positives for Client 3: 207\n",
      "True Negatives for Client 3: 1449\n",
      "False Negatives for Client 3: 207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/jupyter/dtids.user01/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "client3_data = pd.read_csv(\"Sisira /trial new/client_3_data.csv\")\n",
    "\n",
    "X = client3_data.drop(columns=[\"Attack Type\"])\n",
    "y = client3_data[\"Attack Type\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "rf_model_client3 = RandomForestClassifier(random_state=42)\n",
    "rf_model_client3.fit(X_train, y_train)\n",
    "\n",
    "model_filename = \"client_3_model.pkl\"\n",
    "joblib.dump(rf_model_client3, f\"{base_path}/{model_filename}\")\n",
    "print(f\"Trained model for Client 3 saved as '{model_filename}'\")\n",
    "\n",
    "y_pred_client3 = rf_model_client3.predict(X_test)\n",
    "\n",
    "accuracy_client3 = accuracy_score(y_test, y_pred_client3)\n",
    "precision_client3 = precision_score(y_test, y_pred_client3, average=\"weighted\")\n",
    "recall_client3 = recall_score(y_test, y_pred_client3, average=\"weighted\")\n",
    "f1_client3 = f1_score(y_test, y_pred_client3, average=\"weighted\")\n",
    "\n",
    "conf_matrix_client3 = confusion_matrix(y_test, y_pred_client3)\n",
    "\n",
    "TP_client3 = conf_matrix_client3.diagonal().sum()\n",
    "FP_client3 = conf_matrix_client3.sum(axis=0) - conf_matrix_client3.diagonal()\n",
    "FN_client3 = conf_matrix_client3.sum(axis=1) - conf_matrix_client3.diagonal()\n",
    "TN_client3 = conf_matrix_client3.sum() - (FP_client3 + FN_client3 + TP_client3)\n",
    "\n",
    "print(\"Confusion Matrix for Client 3:\\n\", conf_matrix_client3)\n",
    "print(f\"Accuracy for Client 3: {accuracy_client3 * 100:.2f}%\")\n",
    "print(f\"Precision for Client 3: {precision_client3:.2f}\")\n",
    "print(f\"Recall for Client 3: {recall_client3:.2f}\")\n",
    "print(f\"F1 Score for Client 3: {f1_client3:.2f}\")\n",
    "\n",
    "print(\"\\nDetailed Classification Report for Client 3:\\n\", classification_report(y_test, y_pred_client3))\n",
    "\n",
    "print(\"\\nTrue Positives for Client 3:\", TP_client3)\n",
    "print(\"False Positives for Client 3:\", FP_client3.sum())\n",
    "print(\"True Negatives for Client 3:\", TN_client3.sum())\n",
    "print(\"False Negatives for Client 3:\", FN_client3.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b39635bb-b811-48f0-81c9-4e8cfe91fbe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model for Client 4 saved as 'client_4_model.pkl'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/jupyter/dtids.user01/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Client 4:\n",
      " [[83679    11     1     2    21     0     0    55     0]\n",
      " [   32    42     0     0     0     0     0     0     0]\n",
      " [    9     0   369     0     0     0     0     0     0]\n",
      " [    5     0     0  5151     4     0     0     0     0]\n",
      " [   50     0     0     2  7781     0     0     0     0]\n",
      " [    1     0     0     0     0     0     0     0     0]\n",
      " [    1     0     0     0     0     0     0     0     0]\n",
      " [   24     0     0     0     3     0     0  3494     0]\n",
      " [    1     0     2     0     0     0     0     0    92]]\n",
      "Accuracy for Client 4: 99.78%\n",
      "Precision for Client 4: 1.00\n",
      "Recall for Client 4: 1.00\n",
      "F1 Score for Client 4: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/jupyter/dtids.user01/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/jupyter/dtids.user01/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detailed Classification Report for Client 4:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      BENIGN       1.00      1.00      1.00     83769\n",
      "         Bot       0.79      0.57      0.66        74\n",
      " Brute Force       0.99      0.98      0.98       378\n",
      "        DDoS       1.00      1.00      1.00      5160\n",
      "         DoS       1.00      0.99      0.99      7833\n",
      "  Heartbleed       0.00      0.00      0.00         1\n",
      "Infiltration       0.00      0.00      0.00         1\n",
      "   Port Scan       0.98      0.99      0.99      3521\n",
      "  Web Attack       1.00      0.97      0.98        95\n",
      "\n",
      "    accuracy                           1.00    100832\n",
      "   macro avg       0.75      0.72      0.73    100832\n",
      "weighted avg       1.00      1.00      1.00    100832\n",
      "\n",
      "\n",
      "True Positives for Client 4: 100608\n",
      "False Positives for Client 4: 224\n",
      "True Negatives for Client 4: 1568\n",
      "False Negatives for Client 4: 224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/jupyter/dtids.user01/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "client4_data = pd.read_csv(\"Sisira /trial new/client_4_data.csv\")\n",
    "\n",
    "X = client4_data.drop(columns=[\"Attack Type\"])\n",
    "y = client4_data[\"Attack Type\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "rf_model_client4 = RandomForestClassifier(random_state=42)\n",
    "rf_model_client4.fit(X_train, y_train)\n",
    "\n",
    "model_filename = \"client_4_model.pkl\"\n",
    "joblib.dump(rf_model_client4, f\"{base_path}/{model_filename}\")\n",
    "print(f\"Trained model for Client 4 saved as '{model_filename}'\")\n",
    "\n",
    "y_pred_client4 = rf_model_client4.predict(X_test)\n",
    "\n",
    "accuracy_client4 = accuracy_score(y_test, y_pred_client4)\n",
    "precision_client4 = precision_score(y_test, y_pred_client4, average=\"weighted\")\n",
    "recall_client4 = recall_score(y_test, y_pred_client4, average=\"weighted\")\n",
    "f1_client4 = f1_score(y_test, y_pred_client4, average=\"weighted\")\n",
    "\n",
    "conf_matrix_client4 = confusion_matrix(y_test, y_pred_client4)\n",
    "\n",
    "TP_client4 = conf_matrix_client4.diagonal().sum()\n",
    "FP_client4 = conf_matrix_client4.sum(axis=0) - conf_matrix_client4.diagonal()\n",
    "FN_client4 = conf_matrix_client4.sum(axis=1) - conf_matrix_client4.diagonal()\n",
    "TN_client4 = conf_matrix_client4.sum() - (FP_client4 + FN_client4 + TP_client4)\n",
    "\n",
    "print(\"Confusion Matrix for Client 4:\\n\", conf_matrix_client4)\n",
    "print(f\"Accuracy for Client 4: {accuracy_client4 * 100:.2f}%\")\n",
    "print(f\"Precision for Client 4: {precision_client4:.2f}\")\n",
    "print(f\"Recall for Client 4: {recall_client4:.2f}\")\n",
    "print(f\"F1 Score for Client 4: {f1_client4:.2f}\")\n",
    "\n",
    "print(\"\\nDetailed Classification Report for Client 4:\\n\", classification_report(y_test, y_pred_client4))\n",
    "\n",
    "print(\"\\nTrue Positives for Client 4:\", TP_client4)\n",
    "print(\"False Positives for Client 4:\", FP_client4.sum())\n",
    "print(\"True Negatives for Client 4:\", TN_client4.sum())\n",
    "print(\"False Negatives for Client 4:\", FN_client4.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca3a22a8-6a35-4dfc-944d-855789e52b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model for Client 5 saved as 'client_5_model.pkl'\n",
      "Confusion Matrix for Client 5:\n",
      " [[83850     7     1     0    11     0    43     1]\n",
      " [   35    36     0     0     0     0     0     0]\n",
      " [    6     0   348     0     0     0     0     0]\n",
      " [    7     0     0  5123     5     0     0     0]\n",
      " [   35     0     0     1  7669     0     0     0]\n",
      " [    0     0     0     0     0     1     0     0]\n",
      " [   23     0     0     0     1     0  3539     0]\n",
      " [    4     0     1     0     1     0     0    84]]\n",
      "Accuracy for Client 5: 99.82%\n",
      "Precision for Client 5: 1.00\n",
      "Recall for Client 5: 1.00\n",
      "F1 Score for Client 5: 1.00\n",
      "\n",
      "Detailed Classification Report for Client 5:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      BENIGN       1.00      1.00      1.00     83913\n",
      "         Bot       0.84      0.51      0.63        71\n",
      " Brute Force       0.99      0.98      0.99       354\n",
      "        DDoS       1.00      1.00      1.00      5135\n",
      "         DoS       1.00      1.00      1.00      7705\n",
      "Infiltration       1.00      1.00      1.00         1\n",
      "   Port Scan       0.99      0.99      0.99      3563\n",
      "  Web Attack       0.99      0.93      0.96        90\n",
      "\n",
      "    accuracy                           1.00    100832\n",
      "   macro avg       0.98      0.93      0.95    100832\n",
      "weighted avg       1.00      1.00      1.00    100832\n",
      "\n",
      "\n",
      "True Positives for Client 5: 100650\n",
      "False Positives for Client 5: 182\n",
      "True Negatives for Client 5: 1092\n",
      "False Negatives for Client 5: 182\n"
     ]
    }
   ],
   "source": [
    "client5_data = pd.read_csv(\"Sisira /trial new/client_5_data.csv\")\n",
    "\n",
    "X = client5_data.drop(columns=[\"Attack Type\"])\n",
    "y = client5_data[\"Attack Type\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "rf_model_client5 = RandomForestClassifier(random_state=42)\n",
    "rf_model_client5.fit(X_train, y_train)\n",
    "\n",
    "model_filename = \"client_5_model.pkl\"\n",
    "joblib.dump(rf_model_client5, f\"{base_path}/{model_filename}\")\n",
    "print(f\"Trained model for Client 5 saved as '{model_filename}'\")\n",
    "\n",
    "y_pred_client5 = rf_model_client5.predict(X_test)\n",
    "\n",
    "accuracy_client5 = accuracy_score(y_test, y_pred_client5)\n",
    "precision_client5 = precision_score(y_test, y_pred_client5, average=\"weighted\")\n",
    "recall_client5 = recall_score(y_test, y_pred_client5, average=\"weighted\")\n",
    "f1_client5 = f1_score(y_test, y_pred_client5, average=\"weighted\")\n",
    "\n",
    "conf_matrix_client5 = confusion_matrix(y_test, y_pred_client5)\n",
    "\n",
    "TP_client5 = conf_matrix_client5.diagonal().sum()\n",
    "FP_client5 = conf_matrix_client5.sum(axis=0) - conf_matrix_client5.diagonal()\n",
    "FN_client5 = conf_matrix_client5.sum(axis=1) - conf_matrix_client5.diagonal()\n",
    "TN_client5 = conf_matrix_client5.sum() - (FP_client5 + FN_client5 + TP_client5)\n",
    "\n",
    "print(\"Confusion Matrix for Client 5:\\n\", conf_matrix_client5)\n",
    "print(f\"Accuracy for Client 5: {accuracy_client5 * 100:.2f}%\")\n",
    "print(f\"Precision for Client 5: {precision_client5:.2f}\")\n",
    "print(f\"Recall for Client 5: {recall_client5:.2f}\")\n",
    "print(f\"F1 Score for Client 5: {f1_client5:.2f}\")\n",
    "\n",
    "print(\"\\nDetailed Classification Report for Client 5:\\n\", classification_report(y_test, y_pred_client5))\n",
    "\n",
    "print(\"\\nTrue Positives for Client 5:\", TP_client5)\n",
    "print(\"False Positives for Client 5:\", FP_client5.sum())\n",
    "print(\"True Negatives for Client 5:\", TN_client5.sum())\n",
    "print(\"False Negatives for Client 5:\", FN_client5.sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ae9e34-af59-4301-b36b-2ac60e1b2985",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
